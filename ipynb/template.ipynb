{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ebcc68",
   "metadata": {},
   "source": [
    "# Template v2.0\n",
    "\n",
    "- Updated: May 17 2022\n",
    "- Author: Matthew Stachyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b818139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1670afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Core image partitioning algorithms                #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "def imPartition(path, images, reference, splices, blackthresh=0.80, bminpixel=5, anomthresh=0.10):\n",
    "    \"\"\"returns partitioned images together with the path to the original image and a label (0 or 1) for \n",
    "    whether it is anomalous.\n",
    "\n",
    "    :param path: path to where the images are.\n",
    "    :param images: dataframe with the images.\n",
    "    :param reference: dictionary of anomaly tags to reference images generated by buildReference().\n",
    "    :param splices: list of splices according to which to splice the images to. Data has form \n",
    "                    [[(rowindex1, rowindex2), (colindex1, colindex2), ...]]\n",
    "    :param blackthresh: float point value between 0 and 1, with default of 0.8, that specifies how pixels\n",
    "                        need to be black to constitute a black image that is rejected.\n",
    "    :param bminpixel: integer value, with default of 5, that specifies the ceiling value for what constitutes\n",
    "                      a black pixel.\n",
    "    :param anomthresh: float point value between 0 and 1, with default of 0.1, that specifies how much of an\n",
    "                       image needs to contains anomalous pixels (i.e., is a pixel part of anomaly) to be \n",
    "                       labeled with a 1.\n",
    "    :returns: list of tuples as (path, numpy array, label of 0 or 1 for whether anomaly is present)\n",
    "    \"\"\"\n",
    "    # maps the part() method to every image in images. This part() method partitions images by the provided\n",
    "    # splices and append images with a label (0 or 1 if anomalous) if they contain enough non-background \n",
    "    # (i.e., are less than 1-blackthresh black).\n",
    "    return [*map(lambda x : part(path, x, reference, splices, blackthresh, bminpixel, anomthresh),\n",
    "               [tup[1] for tup in list(images.itertuples())])]  # list of image names/paths\n",
    "\n",
    "\n",
    "def part(path, im, ref, splices, bthresh=0.8, minbpixel=5, athresh=0.1):\n",
    "    \"\"\"returns labeled (0 - nonanomalous, 1 - anomalous) partitions of the inputted image.\n",
    "\n",
    "    NOTE  parameters described in imPartition.\n",
    "    \"\"\"\n",
    "    # termination condition:\n",
    "    # the image doesn't return a proper tag or contains only the anomaly\n",
    "    tag = getTag(im)\n",
    "    if not tag or \"anomaly_only_view\" in im: return\n",
    "\n",
    "    # part input image according to input slices, keeping those partitions that are not too\n",
    "    # black and labeling them according to whether they are anomalous or not\n",
    "    refim = ref[tag]\n",
    "    npim  = toNP(path, im)\n",
    "    return [labelPart(im, npim, refim, s[0], s[1], athresh)  # s[0] is the row tuple and s[1] is the column tuple\n",
    "                      for s in splices\n",
    "                      if checkPart(npim, s[0], s[1], bthresh, minbpixel)]\n",
    "\n",
    "\n",
    "def buildReference(path, ims, minpixel=5):\n",
    "    \"\"\"returns dictionary of tag:reference pairs where tag is the \"P/d/d\" anomaly tag and the reference\n",
    "       is an array with all 0s except for 1s where an anomaly is present at that pixel\n",
    "\n",
    "    :param path: path to where the images are.\n",
    "    :param ims: dataframe with the images.\n",
    "    :param minpixel: integer value, with default of 5, that specifies the ceiling value for what constitutes\n",
    "                     a black pixel.\n",
    "    :returns: dictionary where keys are the string anomaly tag and values are numpy arrays with 1s at the pixel\n",
    "              value where there is anomaly present.\n",
    "    \"\"\"\n",
    "    # helper: builds reference image that \"traces\" the anomaly and returns\n",
    "    # an array with 1s at pixels where anomaly is\n",
    "    def build(reference):\n",
    "        zeros = np.zeros((len(reference), len(reference[0])))\n",
    "        for i in range(len(reference)):\n",
    "            for j in range(len(reference[i])):\n",
    "                if np.all(reference[i][j] > minpixel):\n",
    "                    BFS(i, j, reference, zeros)\n",
    "        return zeros\n",
    "\n",
    "\n",
    "    # helper: identifies which pixels contain anomaly using breadth first search,\n",
    "    # looping through every pixel until we find an anomalous one, then considering every\n",
    "    # neighbor that is anomalous until none are left / all are visited\n",
    "    # assumption: there is only one anomaly in each image\n",
    "    def BFS(row, col, reference, zeros):\n",
    "        if row > len(reference)-1 or col > len(reference[0])-1 or row <0 or col <0: return\n",
    "        if zeros[row][col]==1: return\n",
    "\n",
    "        pixel = reference[row][col]\n",
    "        if np.all(pixel > minpixel):\n",
    "            zeros[row][col] = 1\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        moves = [(1,1), (-1,-1), (1,-1), (-1,1), (1,0), (0,1), (-1,0), (0,-1)]\n",
    "        for m in moves:\n",
    "            BFS(row+m[0], col+m[1], reference, zeros)\n",
    "\n",
    "\n",
    "    # assumption: there exists an \"anomaly only view\" version of every image that can be \"traced\" to\n",
    "    # identify which pixels are anomalous versus not anomalous using the above build and BFS methods\n",
    "    # for each tag, builds reference image from zeros array by running BFS on the first pixel\n",
    "    # that is non black, converting 0s to 1s for all adjacent pixels that are non black\n",
    "    references = {}\n",
    "    for i in ims.iterrows():\n",
    "        imname = i[1][0]\n",
    "        tag = getTag(imname) if getTag(imname) else \"\"\n",
    "        if tag and tag not in references.keys():\n",
    "            func = lambda x: (\"anomaly_only_view\" in str(x)) and (tag in str(x))\n",
    "\n",
    "            # grab the next image (as its name in the df) that is a full image and has the anomaly in\n",
    "            # the correct position (i.e., there is a match on the anomaly tag that is part of the name)\n",
    "            reference = next(filter(func, [tup[1]  # holds the image name, whereas tup[0] holds the index\n",
    "                                           for tup\n",
    "                                           in list(ims.itertuples())]))\n",
    "            references[tag] = build(toNP(path, reference)[:, :, :3])\n",
    "    return references\n",
    "\n",
    "\n",
    "def createSplices(path, im, mode='square', dim=64, k=None):\n",
    "    \"\"\"returns list of splices according to which to partition the image to.\n",
    "\n",
    "    :param path: directory where the images are.\n",
    "    :param im: numpy array of the image.\n",
    "    :param mode: the type of partition algorithm used, with 'square' as default, and 'variable' as an option.\n",
    "                 'Square' partitions the image into dim by dim partitions provided the input dim evenly \n",
    "                 divides the image dimensions. 'Variable' \n",
    "    :param dim: integer value specifying the dimension value used for partitioning.\n",
    "    :returns: a method call that performs the specified partition algorithm in the mode parameter.\n",
    "\n",
    "    NOTE  can add new modes for splicing in the future easily here together with a method to perform the\n",
    "          partition.\n",
    "    \"\"\"\n",
    "    if mode == 'square' and len(toNP(path, im))%dim!=0:\n",
    "        raise AttributeError(\"'dim' of %d does not evenly divide image dimension %d by %d\" % (xdim, len(npim), len(npim[0])))\n",
    "    if mode == 'square':\n",
    "        return squareSplice(path, im, dim)\n",
    "    if mode == 'variable':\n",
    "        return variableSplice(path, im, dim, k)\n",
    "\n",
    "\n",
    "def squareSplice(path, im, dim):\n",
    "    \"\"\"return list of square (dim by dim) splices for the images.\n",
    "\n",
    "    :param path: directory where the images are.\n",
    "    :param im: numpy array of the image.\n",
    "    :returns: splices that can be iterated over to generate partitions; these splices have the form of a list\n",
    "              lists with tuples where the tuples contain the row and column splices for the partition.\n",
    "    \"\"\"\n",
    "    npim = toNP(path, im)\n",
    "    return [[(r, r+dim),(c, c+dim)]\n",
    "            for r in range(0, len(npim), dim)\n",
    "            for c in range(0, len(npim), dim)]\n",
    "\n",
    "def variableSplice(path, im, dim, k):\n",
    "    \"\"\"return list of 2-tuples with indices of partitions of image, where image is a numpy array,\n",
    "    integer ydim is used to generate the row windows of the partitions, and integer k is the number\n",
    "    of features to extract\n",
    "\n",
    "    :param path: directory where the images are.\n",
    "    :param im: numpy array of the image.\n",
    "    :param dim: integer value specifying the dimension value used for partitioning.\n",
    "    :param k: the 'variable' or number of edges to identify in the image, used to generate splices.\n",
    "    :returns: splices that can be iterated over to generate partitions; these splices have the form of a list\n",
    "              lists with tuples where the tuples contain the row and column splices for the partition.\n",
    "    \"\"\"\n",
    "    # build kMaxDiffs to store the k largest differences between successive column sums of pixel values\n",
    "    # assumptions: \n",
    "    # - large differences in column pixel sums represent edges (such as the outlines of cargo containers)\n",
    "    # - no vertical feature occurs more often than every 5 pixels and the cargo is at least 5 pixels wide\n",
    "    #   giving us a featureWidth of 5\n",
    "    # algorithm: get sum of pixel values for each column. then get difference between column\n",
    "    # i and i-1. the greatest differences represent the greatest changes from dark to light,\n",
    "    # or from no feature to some feature in the image.\n",
    "    featureWidth = 5\n",
    "    batchSize    = 64\n",
    "    npim         = toNP(path, im)\n",
    "    npim         = npim[:,:,:3].sum(axis=2)  # drop alpha channel and sum RGB channels\n",
    "    \n",
    "    colValues = []\n",
    "    for col in range(len(npim[0])):\n",
    "        rsum, count = 0, 0\n",
    "        for i in range(len(npim[:][col])):\n",
    "            pixel = npim[i][col]\n",
    "            if pixel > 30:\n",
    "                count += 1\n",
    "                rsum += pixel\n",
    "        if count != 0:\n",
    "            colValues.append(rsum/count)\n",
    "        else:\n",
    "            colValues.append(0)\n",
    "  \n",
    "    batchDiffs, maxDiffs, kMaxDiffs = [], [], []\n",
    "    for i in range(1, len(colValues)):\n",
    "        diff = abs((colValues[i] - colValues[i-1]))\n",
    "        if len(kMaxDiffs) < k: kMaxDiffs.append((i, diff))  # 2-tuples as (index, difference)\n",
    "        batchDiffs.append((i, diff))\n",
    "\n",
    "        # algorithm: get max of last 5 col differences (i.e., batch 5 pixel sums using our feature width)\n",
    "        if i%featureWidth==0:\n",
    "            maxBatchDiff = sorted(batchDiffs, key=lambda tup : tup[1], reverse=True)[0]\n",
    "            maxDiffs.append(maxBatchDiff)\n",
    "            batchDiffs = []\n",
    "\n",
    "        # for each batch, grab the largest difference and append to k max diffs.\n",
    "        # if its larger than any, replacing the smallest. this per batch process also ensures\n",
    "        # an O(n) sort rather than O(nlogn) sort.\n",
    "        if i%batchSize==0:\n",
    "            maxDiff = sorted(maxDiffs, key=lambda tup : tup[1], reverse=True)[0][1]\n",
    "            if any(list(map(\n",
    "                    lambda x : x[1] < maxDiff,\n",
    "                    kMaxDiffs))):\n",
    "                diffOnly                   = [x[1] for x in kMaxDiffs]\n",
    "                minLargest                 = min(diffOnly)\n",
    "                minLargestIndex            = list(diffOnly).index(minLargest)\n",
    "                kMaxDiffs[minLargestIndex] = (i, maxDiff)\n",
    "            maxDiffs = []\n",
    "\n",
    "    # assumption: hinges in door are equidistant so we can set the new x to be the\n",
    "    # dfference between the first two values\n",
    "    # algorithm: create k+1 windows of new x dimension by old y dimension (the\n",
    "    # parameter dim) using kLargestDiffs, which is a list of 2-tuples of form\n",
    "    # (index, difference) with the k largest differences in the image.\n",
    "    kMaxDiffs.sort(key=lambda x : x[0])  # sort by index\n",
    "    print(kMaxDiffs)\n",
    "    xdim       = int(kMaxDiffs[1][0] - kMaxDiffs[0][0])  # set uniform x dimension\n",
    "    startIndex = kMaxDiffs[0][0]  # grab first index\n",
    "    return [[(r, r+dim),(c, c+xdim)]\n",
    "            for c in range(startIndex, xdim*(k), xdim)\n",
    "            for r in range(0, len(npim), dim)]\n",
    "\n",
    "\n",
    "def checkPart(im, rsplice, csplice, bthresh, bminpixel):\n",
    "    \"\"\"returns True if partition is OK to include (i.e., is not too black); False, otherwise.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    xdim = rsplice[1] - rsplice[0]\n",
    "    ydim = csplice[1] - csplice[0]\n",
    "    part = im[rsplice[0]:rsplice[1], csplice[0]:csplice[1]][:, :, :3]\n",
    "\n",
    "    # bratio is the ratio of pixels where the RGB value is greater than the inputted min pixel\n",
    "    # value for black, giving is a measure of how \"black\" a pixel\n",
    "    # this then returns whether the ratio is under the threshold, which if it is, means the\n",
    "    # part is not too black to include in training\n",
    "    bratio = sum([0 if np.all(part[r][c] > bminpixel) else 1  # check if each pixel is greater than min\n",
    "                    for r in range(xdim)\n",
    "                    for c in range(ydim)]) / (xdim * ydim)\n",
    "    return bratio < bthresh\n",
    "\n",
    "\n",
    "def labelPart(imname, im, ref, rsplice, csplice, athresh):\n",
    "    \"\"\"returns 3-tuple of form (name of partitioned image, numpy array of partitioned image, 0 if nonanomalous; else 1).\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    xdim = csplice[1] - csplice[0]\n",
    "    ydim = rsplice[1] - rsplice[0]\n",
    "    part = im[rsplice[0]:rsplice[1], csplice[0]:csplice[1]][:, :, :3]\n",
    "    \n",
    "    # aratio is the sum of pixel values in the reference for this splice divided by\n",
    "    # the total number of pixels, giving us how much of the splice is anomalous\n",
    "    # ref[r][c] is 1 pixel in the part generated from the inputted row and col splice\n",
    "    aratio = sum([0 if ref[r][c] == 0 else 1\n",
    "                    for r in range(rsplice[0], rsplice[1])\n",
    "                    for c in range(csplice[0], csplice[1])]) / (xdim * ydim)\n",
    "    return (imname, part, 1) if aratio > athresh else (imname, part, 0)\n",
    "\n",
    "\n",
    "def saveParts(partedIms, anompath, noanompath):\n",
    "    \"\"\"saves partitioned images to disk in up to 2 different locations for anomalous\n",
    "       versus non-anomalous images.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    for i in range(len(partedIms)):\n",
    "        for j in range(len(partedIms[i])):\n",
    "            imname  = partedIms[i][j][0][:-4]\n",
    "            imarray = partedIms[i][j][1]\n",
    "            imlabel = partedIms[i][j][2]\n",
    "            im      = Image.fromarray(imarray)\n",
    "            impath  = anompath if imlabel==1 else noanompath\n",
    "            name    = os.path.join(impath, imname + str(i) + \"_\" + str(j) + \".png\")\n",
    "            im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "548596c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Utils                                             #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "def underSamp(x0, x1, ratio=[4,1]):\n",
    "    \"\"\"return randomized subset of the larger array corresponding to the inputted ratio.\n",
    "\n",
    "    NOTE  x0 has form [(numpy array, 0)]\n",
    "    NOTE  x1 has form [(numpy array, 1)]\n",
    "    NOTE  ratio has form [int1, int2] describing ratio to balance x0 and x1\n",
    "    NOTE  return has form [[(numpy array, 0)], [(numpy array, 1)]], which is a list\n",
    "          of lists where each has size corresponding to the inputted ratio.\n",
    "    \"\"\"\n",
    "    whichtosubset = 0 if len(x0) > ((ratio[0] / sum(ratio)) * (len(x0) + len(x1))) else 1\n",
    "    if whichtosubset==0:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    else:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    indicescount = len(x1) * ratio[0] if whichtosubset==0 else len(x0)//ratio[0]\n",
    "    indices      = [i for i in range(len(tosubset))]\n",
    "    rindices     = random.sample(indices, indicescount)\n",
    "    return [tup\n",
    "            for i, tup in enumerate(tosubset)\n",
    "            if i in rindices], returnas\n",
    "\n",
    "\n",
    "def getTag(im):\n",
    "    \"\"\"return substring of image path string that represents anomaly positions.\n",
    "\n",
    "    NOTE  different image naming convention will require different tagging\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\"[pP]\\d{2}\")\n",
    "    tag     = [split for split in im.split(\"_\") if pattern.match(split)]\n",
    "    return tag[0] if tag else \"\"\n",
    "\n",
    "\n",
    "def storeIms(ims, directory, tag=None):\n",
    "    \"\"\"save numpy images as pngs locally.\n",
    "    \"\"\"\n",
    "    for i in range(len(ims)):\n",
    "        for j in range(len(ims[i])):\n",
    "            name = directory + tag + \"_\" + str(i) + \"_\" + str(j) + \".png\"\n",
    "            im   = Image.fromarray(ims[i][j])\n",
    "            im.save(name)\n",
    "\n",
    "\n",
    "def getIms(path):\n",
    "    \"\"\"return pandas dataframe with paths of pngs.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame([im for im in os.listdir(path) if im[-3:]=='png'])\n",
    "\n",
    "\n",
    "def getImTypes(ims):\n",
    "    \"\"\"get image types for use with method subset_imgs.\n",
    "    \"\"\"\n",
    "    return list(set([row[0].split(\"_\")[1] for _, row in ims.iterrows()]))\n",
    "\n",
    "\n",
    "def toNP(path, im):\n",
    "    \"\"\"return image img as numpy array.\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(os.path.join(path, im)))\n",
    "\n",
    "\n",
    "def openIm(npim):\n",
    "    \"\"\"display inline numpy image img.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (25,10))\n",
    "    plt.imshow(npim)\n",
    "\n",
    "\n",
    "def subsetIms(ims, imtype, leaveout=False, types=\n",
    "              ['Shirts', 'Paper', 'Laptops', 'Cans', 'Bananas', 'Shoes',\n",
    "               'Apples', 'Tires', 'AnomalyAbsent', '200', '750']):\n",
    "\n",
    "    \"\"\"get subset of images of some type (i.e., string like '200', 'AnomalyAbsent', or 'Apples').\n",
    "\n",
    "    NOTE  constrains types we can subset by the default value for List[str] in method definition.\n",
    "    \"\"\"\n",
    "    if imtype not in types: raise AttributeError\n",
    "    return ims[ims[0].str.contains(imtype, case=False) != leaveout]\n",
    "\n",
    "\n",
    "def getRefIm(imdf):\n",
    "    \"\"\"return an image path (name) for a full image that isn't just the anomaly.\n",
    "    \"\"\"\n",
    "    return next(filter(lambda x : \"anomaly_only_view\" not in x, [tup[1] for tup in list(imdf.itertuples())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "427e0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# NOTE  update below to features such as which image\n",
    "#       type of image to partition on, the partition\n",
    "#       algorithm, and file path locations.\n",
    "\n",
    "DIR         = os.path.join(os.path.dirname(os.getcwd()))            \n",
    "SUBTYPE     = 'Shoes'      # which subtype of images to grab, if any else \"\"\n",
    "MODE        = 'variable'   # either 'square' (dim by dim splices) or 'variable' (based on detected edges)\n",
    "K           = {'Shirts': 5, \n",
    "               'Paper': 5, \n",
    "               'Laptops': 4, \n",
    "               'Cans': 4, \n",
    "               'Bananas': 4, \n",
    "               'Shoes': 10,\n",
    "               'Apples': 4, \n",
    "               'Tires': 3}\n",
    "DIM         = 64  # dim for 'square' partition mode or y dim for 'variable' partition mode\n",
    "PATH        = os.path.join(DIR, 'images')\n",
    "ANOMPATH    = os.path.join(PATH, 'partitioned', MODE, 'anom', SUBTYPE)\n",
    "NOANOMPATH  = os.path.join(PATH, 'partitioned', MODE, 'noanom', SUBTYPE)\n",
    "ANOMFILE    = os.path.join(ANOMPATH, str(SUBTYPE + str(1) + \".npy\"))\n",
    "NOANOMFILE  = os.path.join(NOANOMPATH, str(SUBTYPE + str(0) + \".npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e4e98db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# NOTE  below should just run without any tweaking;\n",
    "#       all tweaking is done above.\n",
    "\n",
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Prepare images                                    #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "if not os.path.exists(NOANOMFILE) and not os.path.exists(ANOMFILE):\n",
    "    imdf = getIms(PATH)\n",
    "    \n",
    "    # temporary hack to remove 'Shirts' images with 200 where anomaly isn't visible\n",
    "    if SUBTYPE=='Laptops': imdf = imdf[~imdf[0].str.contains(\"200\")]\n",
    "        \n",
    "    imdf      = subsetIms(imdf, SUBTYPE)\n",
    "    reference = buildReference(PATH, imdf)\n",
    "    refim     = getRefIm(imdf)  \n",
    "    splices   = createSplices(PATH, refim, mode=MODE, dim=DIM, k=K[SUBTYPE])  \n",
    "    partimgs  = imPartition(PATH, imdf, reference, splices)\n",
    "\n",
    "    part0, part1 = [], []\n",
    "    parts = []\n",
    "    for p in partimgs:\n",
    "        if isinstance(p, list):\n",
    "            parts.append(p)\n",
    "            for i in range(len(p)):\n",
    "                if p[i][2]==0:\n",
    "                    part0.append((p[i][1], p[i][2]))\n",
    "                elif p[i][2]==1:\n",
    "                    part1.append((p[i][1], p[i][2]))\n",
    "    np.save(NOANOMFILE, part0, allow_pickle=True)\n",
    "    np.save(ANOMFILE, part1, allow_pickle=True)\n",
    "    saveParts(parts, ANOMPATH, NOANOMPATH)\n",
    "    \n",
    "\n",
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Build dataset                                     #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "part0 = np.load(NOANOMFILE, allow_pickle=True)\n",
    "part1 = np.load(ANOMFILE, allow_pickle=True)\n",
    "\n",
    "part0, part1 = underSamp(part0, part1)                                    # 80:20 distribution, by default\n",
    "xfunc = lambda x : (np.asarray(x[0], dtype=\"float\") /                     # normalize and flatten\n",
    "                    np.linalg.norm(np.asarray(x[0], dtype=\"float\"))).flatten()\n",
    "yfunc = lambda x : np.asarray(x[1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef6f18",
   "metadata": {},
   "source": [
    "## Example running above algorithms with SVM:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b502d4",
   "metadata": {},
   "source": [
    "#### Results as of  May 22\n",
    "- Working types: Shirts, Apples, Paper, Bananas, Tires, Shoes\n",
    "- Non working types: Cans, Shirts\n",
    "- Perfect classification: Apples, Tires, Bananas\n",
    "--- \n",
    "#### Best confusion matrices by type \n",
    "Note: below confusion matrices are with grid search on a predefined hyperparameter grid above <br>\n",
    "\n",
    "- Apples: <br>\n",
    "[[29  0] <br>\n",
    " [ 0  7]] <br> 1.0 <br> {'C': 1000, 'degree': 4, 'gamma': 0.1, 'kernel': 'rbf'} <br><br>\n",
    "- Shirts: <br>\n",
    "[[11  0] <br>\n",
    " [ 3 0]] <br> 0.7857142857142857<br> {'C': 0.1, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'} <br><br>\n",
    "- Bananas: <br>\n",
    "[[25  0] <br>\n",
    " [ 0  5]] <br> 1.0 <br> {'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'} <br><br>\n",
    "- Tires:\n",
    "<br>\n",
    "[[5  0] <br>\n",
    " [ 0  1]] <br> 1.0 <br> {'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'poly'} <br><br>\n",
    "- Shoes:\n",
    "<br>\n",
    "[[45  0] <br>\n",
    " [ 3  9]] <br> 0.9473684210526315 <br> {'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'} <br> <br>\n",
    "- Laptops:\n",
    "<br>\n",
    "[[11  0] <br>\n",
    " [ 3  0]] <br> 0.7857142857142857 <br> {'C': 0.1, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'} <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a9408844",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results below for:  Shoes \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        45\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.39      0.50      0.44        57\n",
      "weighted avg       0.62      0.79      0.70        57\n",
      "\n",
      "[[45  0]\n",
      " [12  0]]\n",
      "0.7894736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        45\n",
      "           1       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.97      0.88      0.91        57\n",
      "weighted avg       0.95      0.95      0.94        57\n",
      "\n",
      "[[45  0]\n",
      " [ 3  9]]\n",
      "0.9473684210526315\n",
      "{'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Support Vector Machine                            #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "print(\"Results below for: \", SUBTYPE, \"\\n\")\n",
    "clf  = svm.SVC(kernel='linear')\n",
    "ypred = clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "print(classification_report(ytest, ypred))\n",
    "print(confusion_matrix(ytest, ypred))\n",
    "print(accuracy_score(ytest, ypred))\n",
    "\n",
    "\n",
    "grid = {'C':[0.1,1,100,1000],\n",
    "        'kernel':['rbf','poly', 'linear'],\n",
    "        'degree':[4, 5, 6, 10, 15],\n",
    "        'gamma': [1, 0.1, 0.01]}\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(grid.score(Xtest, ytest))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cf399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
