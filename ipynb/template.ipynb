{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ebcc68",
   "metadata": {},
   "source": [
    "# Template v2.0\n",
    "\n",
    "- Updated: May 17 2022\n",
    "- Author: Matthew Stachyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b818139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1670afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Core image partioning algorithms                  #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "def imPartition(path, images, reference, splices, blackthresh=0.80, bminpixel=5, anomthresh=0.10):\n",
    "    \"\"\"returns (dim)**2 dimension images as numpy arrays with a tag - 0 or 1, indicating whether an anomaly is\n",
    "       present or not -- provided they do not exceed the exclusion threshold (i.e., are not too black).\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    return [*map(lambda x : part(path, x, reference, splices, blackthresh, bminpixel, anomthresh),\n",
    "               [tup[1] for tup in list(images.itertuples())])]  # list of image names/paths\n",
    "\n",
    "\n",
    "def part(path, im, ref, splices, bthresh=0.8, minbpixel=5, athresh=0.1):\n",
    "    \"\"\"returns labeled (0 - nonanomalous, 1 - anomalous) partitions of the inputted image\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "\n",
    "    NOTE  splices has form [[(rowindex1, rowindex2), (colindex1, colindex2), ...]]\n",
    "    \"\"\"\n",
    "    # termination condition 1:\n",
    "    # the image doesn't return a proper tag or contains only the anomaly\n",
    "    tag = getTag(im)\n",
    "    if not tag or \"anomaly_only_view\" in im: return\n",
    "\n",
    "    # part input image according to input slices, keeping those partitions that are not too\n",
    "    # black and labeling them according to whether they are anomalous or not\n",
    "    refim = ref[tag]\n",
    "    npim  = toNP(path, im)\n",
    "    return [labelPart(im, npim, refim, s[0], s[1], athresh)  # s[0] is the row tuple and s[1] is the column tuple\n",
    "                      for s in splices\n",
    "                      if checkPart(npim, s[0], s[1], bthresh, minbpixel)]\n",
    "\n",
    "\n",
    "def buildReference(path, ims, minpixel=5):\n",
    "    \"\"\"returns dictionary of tag:reference pairs where tag is the \"P/d/d\" anomaly tag and the reference\n",
    "       is an array with all 0s except for 1s where an anomaly is present at that pixel\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    # helper: builds reference image that \"traces\" the anomaly and returns\n",
    "    # an array with 1s at pixels where anomaly is\n",
    "    def build(reference):\n",
    "        zeros = np.zeros((len(reference), len(reference[0])))\n",
    "        for i in range(len(reference)):\n",
    "            for j in range(len(reference[i])):\n",
    "                if np.all(reference[i][j] > minpixel):\n",
    "                    BFS(i, j, reference, zeros)\n",
    "        return zeros\n",
    "\n",
    "    # assumption: there is only one anomaly in each image\n",
    "    # helper: identifies which pixels contain anomaly using breadth first search,\n",
    "    # looping through every pixel until we find an anomalous one, then considering every\n",
    "    # neighbor that is anomalous until none are left / all are visited\n",
    "    def BFS(row, col, reference, zeros):\n",
    "        if row > len(reference)-1 or col > len(reference[0])-1 or row <0 or col <0: return\n",
    "        if zeros[row][col]==1: return\n",
    "\n",
    "        pixel = reference[row][col]\n",
    "        if np.all(pixel > minpixel):\n",
    "            zeros[row][col] = 1\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        moves = [(1,1), (-1,-1), (1,-1), (-1,1), (1,0), (0,1), (-1,0), (0,-1)]\n",
    "        for m in moves:\n",
    "            BFS(row+m[0], col+m[1], reference, zeros)\n",
    "\n",
    "\n",
    "    # assumption: there exists an \"anomaly only view\" version of every image that can be \"traced\" to\n",
    "    # identify which pixels are anomalous versus not anomalous using the above build and BFS methods\n",
    "    # design: for each tag, builds reference image from zeros array by running BFS on the first pixel\n",
    "    # that is non black, converting 0s to 1s for all adjacent pixels that are non black\n",
    "    references = {}\n",
    "    for i in ims.iterrows():\n",
    "        imname = i[1][0]\n",
    "        tag = getTag(imname) if getTag(imname) else \"\"\n",
    "        if tag and tag not in references.keys():\n",
    "            func = lambda x: (\"anomaly_only_view\" in str(x)) and (tag in str(x))\n",
    "\n",
    "            # grab the next image (as its name in the df) that is a full image and has the anomaly in\n",
    "            # the correct position\n",
    "            reference = next(filter(func, [tup[1]  # holds the image name, whereas tup[0] holds the index\n",
    "                                           for tup\n",
    "                                           in list(ims.itertuples())]))\n",
    "            references[tag] = build(toNP(path, reference)[:, :, :3])\n",
    "    return references\n",
    "\n",
    "\n",
    "def createSplices(path, im, mode, dim, k=None):\n",
    "    \"\"\"returns list of splices according to which to partition the image to.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "\n",
    "    NOTE  can add new modes for splicing in the future easily here.\n",
    "    \"\"\"\n",
    "    if mode == 'default' and len(toNP(path, im))%dim!=0:\n",
    "        raise AttributeError(\"'dim' of %d does not evenly divide image dimension %d by %d\" % (xdim, len(npim), len(npim[0])))\n",
    "    if mode == 'default':\n",
    "        return defaultSplice(path, im, dim)\n",
    "    if mode == 'feature':\n",
    "        return featureSplice(path, im, dim, k)\n",
    "\n",
    "\n",
    "def defaultSplice(path, im, xydim):\n",
    "    \"\"\"return list of dim by dim splices for the images.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    npim = toNP(path, im)\n",
    "    return [[(r, r+xydim),(c, c+xydim)]\n",
    "            for r in range(0, len(npim), xydim)\n",
    "            for c in range(0, len(npim), xydim)]\n",
    "\n",
    "def featureSplice(path, im, ydim, k):\n",
    "    \"\"\"return list of 2-tuples with indices of partitions of image, where image is a numpy array,\n",
    "    integer dim is used to generate the row windows of the partitions, and integer k is the number\n",
    "    of features to extract\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "\n",
    "    NOTE  currently sets a uniform dimension for every image\n",
    "    \"\"\"\n",
    "    # build kLargestDiffs to store differences between successive column sums of pixel values\n",
    "    # assumption: large differences in column pixel sums represent edges (such as\n",
    "    # the truck door hinges)\n",
    "    # algorithm: get sum of pixel values for each column. then get difference between column\n",
    "    # i and i-1. the greatest differences represent the greatest changes from dark to light,\n",
    "    # or from no feature to some feature in the image.\n",
    "    featureWidth = 5\n",
    "    batchSize    = ydim // featureWidth\n",
    "    npim         = toNP(path, im)\n",
    "    summedImage  = npim[:,:,:3].sum(axis=2)  # drop alpha channel and sum RGB channels\n",
    "    colSums      = [sum(summedImage[:, c]) for c in range(len(summedImage))]\n",
    "    batchDiffs, maxDiffs, kMaxDiffs = [], [], []\n",
    "    for i in range(1, len(colSums)):\n",
    "        diff = abs((colSums[i] - colSums[i-1]))\n",
    "        if len(kMaxDiffs) < k: kMaxDiffs.append((i, diff))  # 2-tuples as (index, difference)\n",
    "        batchDiffs.append((i, diff))\n",
    "\n",
    "        # assumptions: no vertical feature occurs more often than every 5 pixels and\n",
    "        # the cargo is at least 5 pixels wide, so this consitutes the featureWidth value\n",
    "        # algorithm: batch 10 pixel sums at a time to ensure we only get 1 column\n",
    "        # per local feature.\n",
    "        if i%featureWidth==0:\n",
    "            maxBatchDiff = sorted(batchDiffs, key=lambda tup : tup[1], reverse=True)[0]\n",
    "            maxDiffs.append(maxBatchDiff)\n",
    "            batchDiffs = []\n",
    "\n",
    "        # for each batch, grab the largest difference and append\n",
    "        # to k largest diffs if its larger than any, replacing the smallest. this\n",
    "        # per batch process also ensures an O(n) sort rather than O(nlogn) sort.\n",
    "        if i%batchSize==0:\n",
    "            maxDiff = sorted(maxDiffs, key=lambda tup : tup[1], reverse=True)[0][1]\n",
    "            if any(list(map(\n",
    "                    lambda x : x[1] < maxDiff,\n",
    "                    kMaxDiffs))):\n",
    "                diffOnly                       = [x[1] for x in kMaxDiffs]\n",
    "                minLargest                     = min(diffOnly)\n",
    "                minLargestIndex                = list(diffOnly).index(minLargest)\n",
    "                kMaxDiffs[minLargestIndex]     = (i, maxDiff)\n",
    "            maxDiffs = []\n",
    "\n",
    "    # assumption: hinges in door are equidistant so we can set the new x to be the\n",
    "    # dfference between the first two values\n",
    "    # algorithm: create k+1 windows of new x dimension by old y dimension (the\n",
    "    # parameter dim) using kLargestDiffs, which is a list of 2-tuples of form\n",
    "    # (index, difference) with the k largest differences in the image.\n",
    "    kMaxDiffs.sort(key=lambda x : x[0])  # sort by index\n",
    "    xdim       = int(kMaxDiffs[1][0] - kMaxDiffs[0][0])  # set uniform x dimension\n",
    "    startIndex = kMaxDiffs[0][0]  # grab first index\n",
    "    return [[(r, r+ydim),(c, c+xdim)]\n",
    "            for c in range(startIndex, xdim*(k), xdim)\n",
    "            for r in range(0, len(npim), ydim)]\n",
    "\n",
    "\n",
    "def checkPart(im, rsplice, csplice, bthresh, bminpixel):\n",
    "    \"\"\"returns True if partition is OK to include (i.e., is not too black); False, otherwise.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    xdim = rsplice[1] - rsplice[0]\n",
    "    ydim = csplice[1] - csplice[0]\n",
    "    part = im[rsplice[0]:rsplice[1], csplice[0]:csplice[1]][:, :, :3]\n",
    "\n",
    "    # bratio is the ratio of pixels where the RGB value is greater than the inputted min pixel\n",
    "    # value for black, giving is a measure of how \"black\" a pixel\n",
    "    # this then returns whether the ratio is under the threshold, which if it is, means the\n",
    "    # part is not too black to include in training\n",
    "    bratio = sum([0 if np.all(part[r][c] > bminpixel) else 1  # check if each pixel is greater than min\n",
    "                    for r in range(xdim)\n",
    "                    for c in range(ydim)]) / (xdim * ydim)\n",
    "    return bratio < bthresh\n",
    "\n",
    "\n",
    "def labelPart(imname, im, ref, rsplice, csplice, athresh):\n",
    "    \"\"\"returns 3-tuple of form (name of partitioned image, numpy array of partitioned image, 0 if nonanomalous; else 1).\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    xdim = csplice[1] - csplice[0]\n",
    "    ydim = rsplice[1] - rsplice[0]\n",
    "    part = im[rsplice[0]:rsplice[1], csplice[0]:csplice[1]][:, :, :3]\n",
    "    \n",
    "    # aratio is the sum of pixel values in the reference for this splice divided by\n",
    "    # the total number of pixels, giving us how much of the splice is anomalous\n",
    "    # ref[r][c] is 1 pixel in the part generated from the inputted row and col splice\n",
    "    aratio = sum([0 if ref[r][c] == 0 else 1\n",
    "                    for r in range(rsplice[0], rsplice[1])\n",
    "                    for c in range(csplice[0], csplice[1])]) / (xdim * ydim)\n",
    "    return (imname, part, 1) if aratio > athresh else (imname, part, 0)\n",
    "\n",
    "\n",
    "def saveParts(partedIms, anompath, noanompath):\n",
    "    \"\"\"saves partitioned images to disk in up to 2 different locations for anomalous\n",
    "       versus non-anomalous images.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :param:\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    for i in range(len(partedIms)):\n",
    "        for j in range(len(partedIms[i])):\n",
    "            imname  = partedIms[i][j][0][:-4]\n",
    "            imarray = partedIms[i][j][1]\n",
    "            imlabel = partedIms[i][j][2]\n",
    "            im      = Image.fromarray(imarray)\n",
    "            impath  = anompath if imlabel==1 else noanompath\n",
    "            name    = os.path.join(impath, imname + str(i) + \"_\" + str(j) + \".png\")\n",
    "            im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7489d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Utils                                             #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "def underSamp(x0, x1, ratio=[4,1]):\n",
    "    \"\"\"return randomized subset of the larger array corresponding to the inputted ratio.\n",
    "\n",
    "    NOTE  x0 has form [(numpy array, 0)]\n",
    "    NOTE  x1 has form [(numpy array, 1)]\n",
    "    NOTE  ratio has form [int1, int2] describing ratio to balance x0 and x1\n",
    "    NOTE  return has form [[(numpy array, 0)], [(numpy array, 1)]], which is a list\n",
    "          of lists where each has size corresponding to the inputted ratio.\n",
    "    \"\"\"\n",
    "    whichtosubset = 0 if len(x0) > ((ratio[0] / sum(ratio)) * (len(x0) + len(x1))) else 1\n",
    "    if whichtosubset==0:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    else:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    indicescount = len(x1) * ratio[0] if whichtosubset==0 else len(x0)//ratio[0]\n",
    "    indices      = [i for i in range(len(tosubset))]\n",
    "    rindices     = random.sample(indices, indicescount)\n",
    "    return [tup\n",
    "            for i, tup in enumerate(tosubset)\n",
    "            if i in rindices], returnas\n",
    "\n",
    "\n",
    "def getTag(im):\n",
    "    \"\"\"return substring of image path string that represents anomaly positions.\n",
    "\n",
    "    NOTE  different image naming convention will require different tagging\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\"[pP]\\d{2}\")\n",
    "    tag     = [split for split in im.split(\"_\") if pattern.match(split)]\n",
    "    return tag[0] if tag else \"\"\n",
    "\n",
    "\n",
    "def storeIms(ims, directory, tag=None):\n",
    "    \"\"\"save numpy images as pngs locally.\n",
    "    \"\"\"\n",
    "    for i in range(len(ims)):\n",
    "        for j in range(len(ims[i])):\n",
    "            name = directory + tag + \"_\" + str(i) + \"_\" + str(j) + \".png\"\n",
    "            im   = Image.fromarray(ims[i][j])\n",
    "            im.save(name)\n",
    "\n",
    "\n",
    "def getIms(path):\n",
    "    \"\"\"return pandas dataframe with paths of pngs.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame([im for im in os.listdir(path) if im[-3:]=='png'])\n",
    "\n",
    "\n",
    "def getImTypes(ims):\n",
    "    \"\"\"get image types for use with method subset_imgs.\n",
    "    \"\"\"\n",
    "    return list(set([row[0].split(\"_\")[1] for _, row in ims.iterrows()]))\n",
    "\n",
    "\n",
    "def toNP(path, im):\n",
    "    \"\"\"return image img as numpy array.\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(os.path.join(path, im)))\n",
    "\n",
    "\n",
    "def openIm(npim):\n",
    "    \"\"\"display inline numpy image img.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (25,10))\n",
    "    plt.imshow(npim)\n",
    "\n",
    "\n",
    "def subsetIms(ims, imtype, leaveout=False, types=\n",
    "              ['Shirts', 'Paper', 'Laptops', 'Cans', 'Bananas', 'Shoes',\n",
    "               'Apples', 'Tires', 'AnomalyAbsent', '200', '750']):\n",
    "\n",
    "    \"\"\"get subset of images of some type (i.e., string like '200', 'AnomalyAbsent', or 'Apples').\n",
    "\n",
    "    NOTE  constrains types we can subset by the default value for List[str] in method definition.\n",
    "    \"\"\"\n",
    "    if imtype not in types: raise AttributeError\n",
    "    return ims[ims[0].str.contains(imtype, case=False) != leaveout]\n",
    "\n",
    "\n",
    "def getRefIm(imdf):\n",
    "    \"\"\"return an image path (name) for a full image that isn't just the anomaly.\n",
    "    \"\"\"\n",
    "    return next(filter(lambda x : \"anomaly_only_view\" not in x, [tup[1] for tup in list(imdf.itertuples())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e98db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# NOTE  update below to control type of image, type\n",
    "#       of partition, and target directories.\n",
    "\n",
    "DIR         = os.path.join(os.path.dirname(os.getcwd()))            \n",
    "SUBTYPE     = 'Apples'      # which subtype of images to grab, if any else \"\"\n",
    "MODE        = 'feature'     # either 'default' or 'feature'\n",
    "PATH        = os.path.join(DIR, 'images')\n",
    "ANOMPATH    = os.path.join(PATH, 'partitioned', MODE, 'anom', SUBTYPE)\n",
    "NOANOMPATH  = os.path.join(PATH, 'partitioned', MODE, 'noanom', SUBTYPE)\n",
    "ANOMFILE    = os.path.join(ANOMPATH, str(SUBTYPE + str(1) + \".npy\"))\n",
    "NOANOMFILE  = os.path.join(NOANOMPATH, str(SUBTYPE + str(0) + \".npy\"))\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Prepare images                                    #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "if not os.path.exists(NOANOMFILE) and not os.path.exists(ANOMFILE):\n",
    "    imdf      = getIms(PATH)\n",
    "    imdf      = subsetIms(imdf, SUBTYPE)\n",
    "    reference = buildReference(PATH, imdf)\n",
    "    refim     = getRefIm(imdf)\n",
    "    splices   = createSplices(PATH, refim, mode='feature', dim=64, k=4)\n",
    "    partimgs  = imPartition(PATH, imdf, reference, splices)\n",
    "\n",
    "    part0, part1 = [], []\n",
    "    parts = []\n",
    "    for p in partimgs:\n",
    "        if isinstance(p, list):\n",
    "            parts.append(p)\n",
    "            for i in range(len(p)):\n",
    "                if p[i][2]==0:\n",
    "                    part0.append((p[i][1], p[i][2]))\n",
    "                elif p[i][2]==1:\n",
    "                    part1.append((p[i][1], p[i][2]))\n",
    "    np.save(NOANOMFILE, part0, allow_pickle=True)\n",
    "    np.save(ANOMFILE, part1, allow_pickle=True)\n",
    "    saveParts(parts, ANOMPATH, NOANOMPATH)\n",
    "    \n",
    "\n",
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Build dataset                                     #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "part0 = np.load(NOANOMFILE, allow_pickle=True)\n",
    "part1 = np.load(ANOMFILE, allow_pickle=True)\n",
    "\n",
    "part0, part1 = underSamp(part0, part1)                                    # 80:20 distribution, by default\n",
    "xfunc = lambda x : (np.asarray(x[0], dtype=\"float\") /                     # normalize and flatten\n",
    "                    np.linalg.norm(np.asarray(x[0], dtype=\"float\"))).flatten()\n",
    "yfunc = lambda x : np.asarray(x[1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a9a76",
   "metadata": {},
   "source": [
    "## Example running above algorithms with SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9408844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/matthewstachyra/.local/share/virtualenvs/DISC-tlMijFAs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90        39\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.41      0.50      0.45        48\n",
      "weighted avg       0.66      0.81      0.73        48\n",
      "\n",
      "[[39  0]\n",
      " [ 9  0]]\n",
      "0.8125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.95      0.99      0.97        48\n",
      "weighted avg       0.98      0.98      0.98        48\n",
      "\n",
      "[[38  1]\n",
      " [ 0  9]]\n",
      "0.9791666666666666\n",
      "{'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "# Support Vector Machine                            #\n",
    "#                                                   #\n",
    "#                                                   #\n",
    "#####################################################\n",
    "\n",
    "clf  = svm.SVC(kernel='linear')\n",
    "ypred = clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "print(classification_report(ytest, ypred))\n",
    "print(confusion_matrix(ytest, ypred))\n",
    "print(accuracy_score(ytest, ypred))\n",
    "\n",
    "\n",
    "grid = {'C':[0.1,1,100,1000],\n",
    "        'kernel':['rbf','poly', 'linear'],\n",
    "        'degree':[4,5,6],\n",
    "        'gamma': [1, 0.1, 0.01]}\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(grid.score(Xtest, ytest))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cf399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
