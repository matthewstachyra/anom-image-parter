{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ebcc68",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b818139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "#import cv2\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1670afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"utils for working with images for the DISC Xray project\n",
    "\"\"\"\n",
    "\n",
    "def get_tag(image) -> str:\n",
    "    \"\"\"return substring of image path string that represents anomaly positions.\n",
    "\n",
    "    :image:pd.series: image path.\n",
    "    :rtype:str:       substring from image path specifiy anomaly.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\"[pP]\\d{2}\")  # /1/ pattern matches existing image name convention\n",
    "    return [split\n",
    "            for split in image.split(\"_\")\n",
    "            if (pattern.match(split))] # /2/ different naming convention will require different tagging approach\n",
    "\n",
    "\n",
    "def store_imgs(images: List[np.ndarray], directory: str, tag: str=None) -> None:\n",
    "    \"\"\"save numpy images as pngs locally.\n",
    "\n",
    "    :images:List[np.ndarray]: numpy images.\n",
    "    \"\"\"\n",
    "    for i in range(len(images)):\n",
    "        for j in range(len(images[i])):\n",
    "            name  = directory + tag + \"_\" + str(i) + \"_\" + str(j) + \".png\"\n",
    "            image = Image.fromarray(images[i][j])\n",
    "            image.save(name)\n",
    "\n",
    "\n",
    "def get_imgs(path: str) -> pd.DataFrame:\n",
    "    \"\"\"return pandas dataframe with paths of pngs.\n",
    "\n",
    "    :path:str:           image path.\n",
    "    :rtype:pd.DataFrame: png paths.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame([img for img in os.listdir(path) if img[-3:]=='png'])\n",
    "\n",
    "\n",
    "def get_imgtypes(images: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"get image types for use with method subset_imgs.\n",
    "\n",
    "    [NOTE] requires indexing row with 0 because iterrows returned Series object.\n",
    "\n",
    "    :images:pd.DataFrame: png paths.\n",
    "    :rtype:set:           set with types of png images.\n",
    "    \"\"\"\n",
    "    return list(set([row[0].split(\"_\")[1] for _, row in images.iterrows()]))\n",
    "\n",
    "\n",
    "def subset_imgs(images: pd.DataFrame, img_type: str, without: bool=False,\n",
    "                types: List[str]=['Shirts', 'Paper', 'Laptops', 'Cans',\n",
    "                                  'Bananas', 'Shoes', 'Apples', 'Tires',\n",
    "                                  'AnomalyAbsent', '200', '750', ]) -> List[str]:\n",
    "    \"\"\"get subset of images of some type (i.e., string like '200', 'AnomalyAbsent', or 'Apples').\n",
    "\n",
    "    [NOTE] constrains types we can subset by the default value for List[str] in method definition.\n",
    "\n",
    "    :df:pd.DataFrame: png paths.\n",
    "    :img_type:str:    image type to subset with or without.\n",
    "    :without:bool:    specifies whether to subset images with or without image type img_type; defaults to\n",
    "                      False to subset images of specified type.\n",
    "    :rtype:List[str]: pandas dataframe with subset of images with specified image type.\n",
    "    \"\"\"\n",
    "\n",
    "    if img_type not in types: raise AttributeError\n",
    "    return images[images[0].str.contains(img_type, case=False) != without]\n",
    "\n",
    "\n",
    "def return_npimg(path, img: str) -> np.ndarray:\n",
    "    \"\"\"return image img as numpy array.\n",
    "\n",
    "    :img:str:          png stored as path.\n",
    "    :rtype:np.ndarray: png as numpy array.\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(os.path.join(path, img)))\n",
    "\n",
    "\n",
    "def open_npimg(npimg: np.ndarray) -> None:\n",
    "    \"\"\"display inline numpy image img.\n",
    "\n",
    "    :npimg:np.ndarray: png as numpy array.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (25,10))\n",
    "    plt.imshow(npimg)\n",
    "\n",
    "\n",
    "def build_referencedict(path, images, minpixel=5) -> dict:\n",
    "    \"\"\"returns dictionary of tag:reference pairs where tag is the \"P/d/d\" anomaly tag and the reference\n",
    "       is an array with all 0s except for 1s where an anomaly is present at that pixel\n",
    "\n",
    "    [CALL CHAIN] (get_tag) <- (BFS <- build <- (build_referencedict)) <- (partition_images)\n",
    "    -----------\n",
    "    :images:pd.DataFrame: images as paths.\n",
    "    :minpixel:            minimum pixel value to classify as non-black as 3D channel.\n",
    "    :rtype:dict:          key is anomaly tag and value is reference array.\n",
    "    \"\"\"\n",
    "\n",
    "    # /1/ builds reference image that \"traces\" the anomaly and returns an array with 1s at pixels where anomaly is\n",
    "    def build(reference):\n",
    "        zeros = np.zeros((len(reference), len(reference[0])))\n",
    "        for i in range(len(reference)):\n",
    "            for j in range(len(reference[i])):\n",
    "                if np.all(reference[i][j] > minpixel):\n",
    "                    BFS(i, j, reference, zeros)\n",
    "        return zeros\n",
    "\n",
    "    # /2/ algorithm used to identify which pixels contain anomaly\n",
    "    def BFS(row, col, reference, zeros):\n",
    "        if row > len(reference)-1 or col > len(reference[0])-1 or row <0 or col <0: return\n",
    "        if zeros[row][col]==1: return\n",
    "\n",
    "        pixel = reference[row][col]\n",
    "        if np.all(pixel > minpixel):\n",
    "            zeros[row][col] = 1\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        moves = [(1,1), (-1,-1), (1,-1), (-1,1), (1,0), (0,1), (-1,0), (0,-1)]\n",
    "        for m in moves:\n",
    "            BFS(row+m[0], col+m[1], reference, zeros)\n",
    "\n",
    "\n",
    "    # /3/ for each tag, builds reference image from zeros array by running BFS on the first pixel that is non black,\n",
    "    #     converting 0s to 1s for all adjacent pixels that are non black\n",
    "    references = {}\n",
    "    for image in images.iterrows():\n",
    "        tag = get_tag(image[1][0])[0] if get_tag(image[1][0]) else \"\"\n",
    "        if tag and tag not in references.keys():\n",
    "            func            = lambda x: (\"anomaly_only_view\" in str(x)) and (tag in str(x))\n",
    "            reference       = next(\n",
    "                                filter(func, [tup[1]\n",
    "                                              for tup\n",
    "                                              in list(images.itertuples())]))\n",
    "            references[tag] = build(return_npimg(path, reference)[:, :, 0])\n",
    "    return references\n",
    "\n",
    "\n",
    "def partition_images(path, images, referencedict, dim=64, blackthresh=0.80, blackminpixel=5, anomthresh=0.10) -> List[tuple]:\n",
    "    \"\"\"returns (dim)**2 dimension images as numpy arrays with a tag - 0 or 1, indicating whether an anomaly is\n",
    "       present or not -- provided they do not exceed the exclusion threshold (i.e., are not too black).\n",
    "\n",
    "    [CALL CHAIN] (get_tag) <- (BFS <- build <- (build_referencedict)) <- (partition_images)\n",
    "    [NOTE]       algorithm only works for non-normalized images. Would need to add parameter otherwise.\n",
    "    ------------\n",
    "    :images:List[str]:       local paths to all pngs (generated using get_subset).\n",
    "\n",
    "    :referencedict:Dict:     key is anomaly tag and value is numpy array (where the 1s represent anomaly amongst 0s)\n",
    "\n",
    "    :dim:int:                pixel length/width of subimages generated. This defaults to 64 for 64x64 images and\n",
    "                             only allows images of integer length/width (i.e., dim evenly divides image).\n",
    "\n",
    "    :blackthresh:float:      used to decide whether subimage is kept; answers question of \"how black does an image\n",
    "                             need to be to be excluded\". The threshold for exclusion is the ratio of black pixels\n",
    "                             to total pixels. Default of 0.80 says \"80% of pixels need to be black\" for an image\n",
    "                             to be excluded.\n",
    "\n",
    "    :blackminpixel:int:      used to define RGB value for notion of \"black\". Default is 5.\n",
    "\n",
    "    :anomthresh:float:       used to decide whether the subimage contains sufficient anomaly to be labeled anomalous.\n",
    "\n",
    "    :rtype:List(tuple):      list of tuples containing subimage of (dim)(dim) dimension and a label of 0 or 1 for whether\n",
    "                             it subimage has anomaly.\n",
    "    \"\"\"\n",
    "\n",
    "    img_dim = len(return_npimg(path, images.iloc[0][0])) # /1/ assumes all images are square and of uniform dimension\n",
    "    if img_dim%dim!=0: raise AttributeError(\"Parameter dim does not evenly divide image dimension\")\n",
    "\n",
    "    # /2/ check if the subimage is not black and therefore OK to append\n",
    "    def underthresh(img: np.ndarray) -> bool:\n",
    "        bratio = sum([0 if img[i][j] > blackminpixel else 1\n",
    "                      for i in range(0, dim)\n",
    "                      for j in range(0, dim)]) / dim**2\n",
    "        return bratio < blackthresh\n",
    "\n",
    "\n",
    "    # /3/ return tuple with image and label (0 if without anomaly, 1 if with anomaly)\n",
    "    def label(name: str, img1: np.ndarray, img2: np.ndarray) -> tuple:\n",
    "        aratio = sum([0 if img1[i][j] == 0 else 1\n",
    "                      for i in range(0, dim)\n",
    "                      for j in range(0, dim)]) / dim**2\n",
    "        return (name, img2, 1) if aratio > anomthresh else (name, img2, 0)\n",
    "\n",
    "\n",
    "    subimages = []\n",
    "    for image in images.iterrows():\n",
    "        img_name = image[1][0]\n",
    "        if get_tag(img_name) and (\"anomaly_only_view\" not in img_name):\n",
    "            npimg = return_npimg(path, img_name)   # /4/ get numpy array of image\n",
    "            tag   = get_tag(img_name)[0]           # /5/ get tag for image\n",
    "            ref   = referencedict[tag]             # /6/ get reference array for image (reference will also be partitioned)\n",
    "\n",
    "            # /7/ adds image if not black with tag 0 or 1 for anomaly\n",
    "            subimages.extend([label(img_name, ref[row-dim:row, col-dim:col], npimg[row-dim:row, col-dim:col])\n",
    "                                for col in range(dim, img_dim+dim, dim)\n",
    "                                for row in range(dim, img_dim+dim, dim)\n",
    "                                if underthresh(npimg[row-dim:row, col-dim:col][:,:,0])]) # /8/ drops Alpha channel\n",
    "    return subimages\n",
    "\n",
    "\n",
    "def save_partitioned(partitionedimgs, anomalypath, noanomalypath):\n",
    "    \"\"\"saves partitioned images to disk in up to 2 different locations for anomalous\n",
    "       versus non-anomalous images.\n",
    "\n",
    "    :partitionedimgs:tuple: tuple returned by partition_images of form (name, array, label).\n",
    "    :anomalypath:str:       path to save anomalous images.\n",
    "    :noanomalypath:str:     path to save nonanomalous images.\n",
    "\n",
    "    :rtype:None\n",
    "    \"\"\"\n",
    "    for i in range(len(partitionedimgs)):\n",
    "        for j in range(len(partitionedimgs[i])):\n",
    "            img_name  = partitionedimgs[i][j][0][:-3]\n",
    "            img_array = partitionedimgs[i][j][1]\n",
    "            img_label = partitionedimgs[i][j][2]\n",
    "            img       = Image.fromarray(img_array)\n",
    "            path      = anomalypath if img_label==1 else noanomalypath\n",
    "            name      = os.path.join(path, img_name + \"_\" + str(i) + \"_\" + str(j) + \".png\")\n",
    "            img.save(name)\n",
    "\n",
    "\n",
    "def undersample(x0, x1, ratio=[4,1]):\n",
    "    \"\"\"return randomized subset of the larger array corresponding to the inputted ratio.\n",
    "\n",
    "    :x0:List(tuple):  of form [(numpy array, 0)]\n",
    "    :x1:List(tuple):  of form [(numpy array, 1)]\n",
    "    :ratio:List(int): of form [int1, int2] describing ratio to balance x0 and x1\n",
    "\n",
    "    :rtype:List(List(tuple)): of form [[(numpy array, 0)], [(numpy array, 1)]], which is a list\n",
    "                              of lists where each has size corresponding\n",
    "                              to the inputted ratio.\n",
    "    \"\"\"\n",
    "    whichtosubset = 0 if len(x0) > ((ratio[0] / sum(ratio)) * (len(x0) + len(x1))) else 1\n",
    "    if whichtosubset==0:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    else:\n",
    "        tosubset = x0\n",
    "        returnas = x1\n",
    "    indicescount = len(x1) * ratio[0] if whichtosubset==0 else len(x0)//ratio[0]\n",
    "    indices      = [i for i in range(len(tosubset))]\n",
    "    rindices     = random.sample(indices, indicescount)\n",
    "    return [tup\n",
    "            for i, tup in enumerate(tosubset)\n",
    "            if i in rindices], returnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e98db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"run utils from here\n",
    "\"\"\"\n",
    "\n",
    "###############################################\n",
    "#                                             #\n",
    "# I. PREPARE IMAGES                           #\n",
    "#                                             #\n",
    "###############################################\n",
    "\n",
    "# edit below\n",
    "DIR         = os.path.join(os.path.pardir, os.getcwd())          \n",
    "PATH        = os.path.join(DIR, \"images/\")                                  \n",
    "NONANOMPATH = \"apples0.npy\"\n",
    "ANOMPATH    = \"apples1.npy\"\n",
    "SUBTYPE     = \"Apples\"  # leave as \"\" if not subtyping\n",
    "\n",
    "if not os.path.exists(NONANOMPATH) and not os.path.exists(ANOMPATH):\n",
    "    imgdf     = get_imgs(PATH)\n",
    "    imgdf     = subset_imgs(imgdf, SUBTYPE)\n",
    "    refdict   = build_referencedict(PATH, imgdf)\n",
    "    partimgs  = partition_images(PATH, imgdf, refdict)\n",
    "    part0     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==0]\n",
    "    part1     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==1]\n",
    "    np.save(ANOMPATH, part1, allow_pickle=True)\n",
    "    np.save(NONANOMPATH, part0, allow_pickle=True)\n",
    "\n",
    "###############################################\n",
    "#                                             #\n",
    "# II. BUILD DATASET                           #\n",
    "#                                             #\n",
    "###############################################\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1]) # 80:20 distribution, by default\n",
    "xfunc = lambda x : (np.asarray(x[0], dtype=\"float\") /   # normalize and flatten\n",
    "                    np.linalg.norm(np.asarray(x[0], dtype=\"float\"))).flatten()\n",
    "yfunc = lambda x : np.asarray(x[1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9408844",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Second Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        18\n",
      "           1       0.88      1.00      0.93        14\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.94      0.94      0.94        32\n",
      "weighted avg       0.95      0.94      0.94        32\n",
      "\n",
      "[[16  2]\n",
      " [ 0 14]]\n",
      "0.9375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "# III. SUPPORT VECTOR MACHINE                 #\n",
    "#                                             #\n",
    "###############################################\n",
    "\n",
    "# clf  = svm.SVC(kernel='linear')\n",
    "# ypred = clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "\n",
    "# print('First Report \\n')\n",
    "# print(classification_report(ytest, ypred))\n",
    "# print(confusion_matrix(ytest, ypred))\n",
    "# print(accuracy_score(ytest, ypred))\n",
    "\n",
    "grid = {'C':[0.1,1,100,1000],\n",
    "        'kernel':['rbf','poly', 'linear'],\n",
    "        'degree':[4,5,6],\n",
    "        'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print('\\n Second Report \\n')\n",
    "print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "print(grid.score(Xtest, ytest))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d899b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f52665",
   "metadata": {},
   "source": [
    "First step: Just looking at apple dataset, take several random samples of the non-anomalous dataset and run various SVCs with an equal ratio of non-anomalous data to anomalous data. Doing a grid search as a first pass on all the different models to then see how everything looks in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5fe6bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 5 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 6 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 7 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 8 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 9 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.86      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "[[13  5]\n",
      " [ 0 14]]\n",
      "0.84375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "grid = {'C':[0.1,1,100,1000],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "for cycle in range(10):\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1]) # 50:50 distribution for the purpose of comparison\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    grid.fit(Xtrain, ytrain)\n",
    "\n",
    "    print('\\n', cycle, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca12c08",
   "metadata": {},
   "source": [
    "OK! I have some number of samples run with random sampling of the non-anomalous dataset in an equal ratio to the anomalous dataset. Given that the confusion matrix and preferred classification is the exact same for each sample, I wonder now if changing my random sampling in the train-test split will give me any meaningful difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa2d0a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90        16\n",
      "           1       0.84      1.00      0.91        16\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.92      0.91      0.91        32\n",
      "weighted avg       0.92      0.91      0.91        32\n",
      "\n",
      "[[13  3]\n",
      " [ 0 16]]\n",
      "0.90625\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        14\n",
      "           1       0.86      1.00      0.92        18\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.93      0.89      0.90        32\n",
      "weighted avg       0.92      0.91      0.90        32\n",
      "\n",
      "[[11  3]\n",
      " [ 0 18]]\n",
      "0.90625\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.95      0.92      0.93        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "[[19  0]\n",
      " [ 2 11]]\n",
      "0.9375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        15\n",
      "           1       0.85      1.00      0.92        17\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.93      0.90      0.90        32\n",
      "weighted avg       0.92      0.91      0.90        32\n",
      "\n",
      "[[12  3]\n",
      " [ 0 17]]\n",
      "0.90625\n",
      "{'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.94      0.94      0.94        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "[[14  2]\n",
      " [ 0 16]]\n",
      "0.9375\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 5 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        15\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.87      0.87      0.87        32\n",
      "weighted avg       0.88      0.88      0.88        32\n",
      "\n",
      "[[13  2]\n",
      " [ 2 15]]\n",
      "0.875\n",
      "{'C': 100, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 6 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        20\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.88      0.90      0.87        32\n",
      "weighted avg       0.91      0.88      0.88        32\n",
      "\n",
      "[[16  4]\n",
      " [ 0 12]]\n",
      "0.875\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 7 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.86      0.82      0.81        32\n",
      "weighted avg       0.87      0.81      0.81        32\n",
      "\n",
      "[[11  6]\n",
      " [ 0 15]]\n",
      "0.8125\n",
      "{'C': 1000, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 8 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.95      0.92      0.93        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "[[11  2]\n",
      " [ 0 19]]\n",
      "0.9375\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 9 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        20\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.90      0.93      0.90        32\n",
      "weighted avg       0.93      0.91      0.91        32\n",
      "\n",
      "[[17  3]\n",
      " [ 0 12]]\n",
      "0.90625\n",
      "{'C': 100, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "for cycle in range(10):\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1]) # 50:50 distribution for the purpose of comparison\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "    \n",
    "    grid.fit(Xtrain, ytrain)\n",
    "\n",
    "    print('\\n', cycle, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fe091",
   "metadata": {},
   "source": [
    "OK! As expected this introduced some variance. I think the next thing that I might do is kfold cross validation on each model that was selected as a \"good model\" by this best grid search. Also: one thing that these models aren't really doing is giving false positives, but instead giving false negatives. Given the application of this work, we might want to preferentially bias our models towards lower total accuracy, but decreasing false negatives/increasing false positives. Given that C is an inverse l^2 penalty, by increasing that this might give a model that's more in line with perfomance that's desired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b55d2",
   "metadata": {},
   "source": [
    "Changing 2 things here:\n",
    "1. Changing the parameter space we sweep over, particularly by changing the regularization value. We'll see what happens regarding \"best performance\" still\n",
    "2. Implementing a 4fold training testing cross-validation method to try and get better model averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff7bc9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        14\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.85      0.82      0.81        26\n",
      "weighted avg       0.86      0.81      0.80        26\n",
      "\n",
      "[[ 9  5]\n",
      " [ 0 12]]\n",
      "0.8076923076923077\n",
      "{'C': 10, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        12\n",
      "           1       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.89      0.88      0.88        26\n",
      "weighted avg       0.89      0.88      0.88        26\n",
      "\n",
      "[[10  2]\n",
      " [ 1 13]]\n",
      "0.8846153846153846\n",
      "{'C': 50, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59        12\n",
      "           1       0.67      1.00      0.80        14\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.83      0.71      0.69        26\n",
      "weighted avg       0.82      0.73      0.70        26\n",
      "\n",
      "[[ 5  7]\n",
      " [ 0 14]]\n",
      "0.7307692307692307\n",
      "{'C': 50, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        14\n",
      "           1       0.69      0.75      0.72        12\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n",
      "[[10  4]\n",
      " [ 3  9]]\n",
      "0.7307692307692307\n",
      "{'C': 50, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "grid = {'C':[0.1,1,10,50,100],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1]) # 50:50 distribution for the purpose of comparison\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=10)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "#Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "\n",
    "    grid.fit(Xtrain, ytrain)\n",
    "\n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dae77",
   "metadata": {},
   "source": [
    "Ok, it appears that a deg 6 poly kernel with gamma 1 and C=50 is doing reasonably well. Given this, let's run a model with these exact parameters on a few different datasets and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44fe0cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 0 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        15\n",
      "           1       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.93      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "[[13  2]\n",
      " [ 0 11]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72        12\n",
      "           1       0.77      0.71      0.74        14\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n",
      "[[ 9  3]\n",
      " [ 4 10]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.77      0.74      0.73        26\n",
      "weighted avg       0.78      0.73      0.72        26\n",
      "\n",
      "[[ 8  6]\n",
      " [ 1 11]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83        11\n",
      "           1       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.85      0.85      0.85        26\n",
      "weighted avg       0.86      0.85      0.85        26\n",
      "\n",
      "[[10  1]\n",
      " [ 3 12]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 1 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.84      0.84      0.84        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "[[ 8  2]\n",
      " [ 2 14]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74        12\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.87      0.79      0.79        26\n",
      "weighted avg       0.86      0.81      0.80        26\n",
      "\n",
      "[[ 7  5]\n",
      " [ 0 14]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        14\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.88      0.86      0.85        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[10  4]\n",
      " [ 0 12]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.95      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[[16  0]\n",
      " [ 1  9]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 2 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.88      0.91      0.88        26\n",
      "weighted avg       0.91      0.88      0.89        26\n",
      "\n",
      "[[14  3]\n",
      " [ 0  9]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        11\n",
      "           1       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.81      0.80      0.80        26\n",
      "weighted avg       0.81      0.81      0.81        26\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 13]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75         7\n",
      "           1       0.94      0.84      0.89        19\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.80      0.85      0.82        26\n",
      "weighted avg       0.87      0.85      0.85        26\n",
      "\n",
      "[[ 6  1]\n",
      " [ 3 16]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.59      0.74        17\n",
      "           1       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.78      0.79      0.73        26\n",
      "weighted avg       0.85      0.73      0.73        26\n",
      "\n",
      "[[10  7]\n",
      " [ 0  9]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 3 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.91      0.88      0.88        26\n",
      "weighted avg       0.90      0.88      0.88        26\n",
      "\n",
      "[[ 9  3]\n",
      " [ 0 14]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.76        13\n",
      "           1       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.86      0.81      0.80        26\n",
      "weighted avg       0.86      0.81      0.80        26\n",
      "\n",
      "[[ 8  5]\n",
      " [ 0 13]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.92      0.92        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "[[ 9  1]\n",
      " [ 1 15]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.88      0.91      0.88        26\n",
      "weighted avg       0.91      0.88      0.89        26\n",
      "\n",
      "[[14  3]\n",
      " [ 0  9]]\n"
     ]
    }
   ],
   "source": [
    "poly_clf = svm.SVC(kernel='poly',degree=6,C=50,gamma=1)\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "for cycle in range(4):\n",
    "    print('\\n##############################\\n RANDOM SAMPLE #',cycle,'\\n##############################\\n')\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True,random_state=cycle)\n",
    "\n",
    "    idx=0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        idx+=1\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        Xtrain, Xtest = X[train_index], X[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        ypred = poly_clf.fit(Xtrain,ytrain).predict(Xtest)\n",
    "        print('\\n', idx, 'th Report \\n')\n",
    "        print(classification_report(ytest, ypred))\n",
    "        print(confusion_matrix(ytest, ypred))\n",
    "        poly_clf.score(Xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e578f",
   "metadata": {},
   "source": [
    "Quick summary:\n",
    "For the apple dataset considering balanced classes with the whole anomaly set and an equal, randomly selected part of the non-anomalous dataset, we trained a variety of SVMs. Following this, we did 4-fold cross validation in an attempt to see how the model performance was doing on a particular SVM. My main takeaways are that we see accurate classification using just a standard SVM, but that we bias towards more false negatives than false positives. This doesn't seem ideal for the application space, so merits further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be167e2f",
   "metadata": {},
   "source": [
    "I think the next thing to do is try this type of analysis on a different dataset and see if there's similar performance (e.g. tires). This should be easy to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60eae350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting tires from util functions\n",
    "DIR         = os.path.join(os.path.pardir, os.getcwd())          \n",
    "PATH        = os.path.join(DIR, \"images/\")                                  \n",
    "NONANOMPATH = \"tires0.npy\"\n",
    "ANOMPATH    = \"tires1.npy\"\n",
    "SUBTYPE     = \"Tires\"  # leave as \"\" if not subtyping\n",
    "\n",
    "if not os.path.exists(NONANOMPATH) and not os.path.exists(ANOMPATH):\n",
    "    imgdf     = get_imgs(PATH)\n",
    "    imgdf     = subset_imgs(imgdf, SUBTYPE)\n",
    "    refdict   = build_referencedict(PATH, imgdf)\n",
    "    partimgs  = partition_images(PATH, imgdf, refdict)\n",
    "    part0     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==0]\n",
    "    part1     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==1]\n",
    "    np.save(ANOMPATH, part1, allow_pickle=True)\n",
    "    np.save(NONANOMPATH, part0, allow_pickle=True)\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0c6f549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87        16\n",
      "           1       0.83      0.94      0.88        16\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.88      0.88      0.87        32\n",
      "weighted avg       0.88      0.88      0.87        32\n",
      "\n",
      "[[13  3]\n",
      " [ 1 15]]\n",
      "0.875\n",
      "{'C': 100, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.96      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "[[13  1]\n",
      " [ 0 18]]\n",
      "0.96875\n",
      "{'C': 100, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        19\n",
      "           1       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.86      0.87      0.84        32\n",
      "weighted avg       0.89      0.84      0.84        32\n",
      "\n",
      "[[14  5]\n",
      " [ 0 13]]\n",
      "0.84375\n",
      "{'C': 50, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.94      0.94      0.94        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "[[15  0]\n",
      " [ 2 15]]\n",
      "0.9375\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72        16\n",
      "           1       0.70      1.00      0.82        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.85      0.78      0.77        32\n",
      "weighted avg       0.85      0.78      0.77        32\n",
      "\n",
      "[[ 9  7]\n",
      " [ 0 16]]\n",
      "0.78125\n",
      "{'C': 1000, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 5 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        15\n",
      "           1       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "[[14  1]\n",
      " [ 0 17]]\n",
      "0.96875\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 6 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        20\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.88      0.84        32\n",
      "weighted avg       0.89      0.84      0.85        32\n",
      "\n",
      "[[15  5]\n",
      " [ 0 12]]\n",
      "0.84375\n",
      "{'C': 50, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 7 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.94      0.94      0.94        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "[[15  2]\n",
      " [ 0 15]]\n",
      "0.9375\n",
      "{'C': 100, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 8 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90        13\n",
      "           1       1.00      0.84      0.91        19\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.91      0.92      0.91        32\n",
      "weighted avg       0.92      0.91      0.91        32\n",
      "\n",
      "[[13  0]\n",
      " [ 3 16]]\n",
      "0.90625\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 9 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        20\n",
      "           1       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.77      0.79      0.78        32\n",
      "weighted avg       0.80      0.78      0.78        32\n",
      "\n",
      "[[15  5]\n",
      " [ 2 10]]\n",
      "0.78125\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "grid = {'C':[0.1,1,10,50,100,1000],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "for cycle in range(10):\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1]) # 50:50 distribution for the purpose of comparison\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "    \n",
    "    grid.fit(Xtrain, ytrain)\n",
    "\n",
    "    print('\\n', cycle, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c1029",
   "metadata": {},
   "source": [
    "Similar performance more or less! We'll now look at a 4-fold cross validation again for a degree 5 polynomial kernel with C=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2682f984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 0 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        15\n",
      "           1       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.96      0.97      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[[14  1]\n",
      " [ 0 11]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.88      1.00      0.93        14\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.94      0.92      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "[[10  2]\n",
      " [ 0 14]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        14\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.88      0.86      0.85        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[10  4]\n",
      " [ 0 12]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.86      0.83      0.84        26\n",
      "weighted avg       0.85      0.85      0.84        26\n",
      "\n",
      "[[ 8  3]\n",
      " [ 1 14]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 1 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        10\n",
      "           1       0.84      1.00      0.91        16\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.92      0.85      0.87        26\n",
      "weighted avg       0.90      0.88      0.88        26\n",
      "\n",
      "[[ 7  3]\n",
      " [ 0 16]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.91      0.88      0.88        26\n",
      "weighted avg       0.90      0.88      0.88        26\n",
      "\n",
      "[[ 9  3]\n",
      " [ 0 14]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        14\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.88      0.86      0.85        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[10  4]\n",
      " [ 0 12]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.92      0.92        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "[[15  1]\n",
      " [ 1  9]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 2 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.85      0.88      0.84        26\n",
      "weighted avg       0.89      0.85      0.85        26\n",
      "\n",
      "[[13  4]\n",
      " [ 0  9]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        11\n",
      "           1       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.89      0.82      0.83        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[ 7  4]\n",
      " [ 0 15]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74         7\n",
      "           1       1.00      0.74      0.85        19\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.79      0.87      0.79        26\n",
      "weighted avg       0.89      0.81      0.82        26\n",
      "\n",
      "[[ 7  0]\n",
      " [ 5 14]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.53      0.89      0.67         9\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.72      0.74      0.69        26\n",
      "weighted avg       0.78      0.69      0.70        26\n",
      "\n",
      "[[10  7]\n",
      " [ 1  8]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 3 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.91      0.88      0.88        26\n",
      "weighted avg       0.90      0.88      0.88        26\n",
      "\n",
      "[[ 9  3]\n",
      " [ 0 14]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63        13\n",
      "           1       0.65      1.00      0.79        13\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.82      0.73      0.71        26\n",
      "weighted avg       0.83      0.73      0.71        26\n",
      "\n",
      "[[ 6  7]\n",
      " [ 0 13]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        10\n",
      "           1       0.86      0.75      0.80        16\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.76      0.78      0.76        26\n",
      "weighted avg       0.78      0.77      0.77        26\n",
      "\n",
      "[[ 8  2]\n",
      " [ 4 12]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        17\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.82      0.85      0.81        26\n",
      "weighted avg       0.88      0.81      0.81        26\n",
      "\n",
      "[[12  5]\n",
      " [ 0  9]]\n"
     ]
    }
   ],
   "source": [
    "poly_clf = svm.SVC(kernel='poly',degree=5,C=50,gamma=1)\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "for cycle in range(4):\n",
    "    print('\\n##############################\\n RANDOM SAMPLE #',cycle,'\\n##############################\\n')\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True,random_state=cycle)\n",
    "\n",
    "    idx=0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        idx+=1\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        Xtrain, Xtest = X[train_index], X[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        ypred = poly_clf.fit(Xtrain,ytrain).predict(Xtest)\n",
    "        print('\\n', idx, 'th Report \\n')\n",
    "        print(classification_report(ytest, ypred))\n",
    "        print(confusion_matrix(ytest, ypred))\n",
    "        poly_clf.score(Xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01b1d8",
   "metadata": {},
   "source": [
    "Now doing the same with bananas just because"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bfb15cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandlersmith/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        17\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.95      0.94      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[17  0]\n",
      " [ 2 14]]\n",
      "0.9393939393939394\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.93      0.95      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[12  0]\n",
      " [ 2 19]]\n",
      "0.9393939393939394\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        21\n",
      "           1       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.93      0.95      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[19  2]\n",
      " [ 0 12]]\n",
      "0.9393939393939394\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        15\n",
      "           1       0.86      1.00      0.92        18\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.93      0.90      0.91        33\n",
      "weighted avg       0.92      0.91      0.91        33\n",
      "\n",
      "[[12  3]\n",
      " [ 0 18]]\n",
      "0.9090909090909091\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        18\n",
      "           1       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.92      0.92      0.91        33\n",
      "weighted avg       0.92      0.91      0.91        33\n",
      "\n",
      "[[15  3]\n",
      " [ 0 15]]\n",
      "0.9090909090909091\n",
      "{'C': 1000, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 5 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83        19\n",
      "           1       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.82      0.82      0.82        33\n",
      "weighted avg       0.83      0.82      0.82        33\n",
      "\n",
      "[[15  4]\n",
      " [ 2 12]]\n",
      "0.8181818181818182\n",
      "{'C': 1000, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 6 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        19\n",
      "           1       0.73      0.79      0.76        14\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.78      0.79      0.78        33\n",
      "weighted avg       0.79      0.79      0.79        33\n",
      "\n",
      "[[15  4]\n",
      " [ 3 11]]\n",
      "0.7878787878787878\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 7 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.94      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[15  2]\n",
      " [ 0 16]]\n",
      "0.9393939393939394\n",
      "{'C': 1000, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 8 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.97      0.97      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n",
      "[[16  0]\n",
      " [ 1 16]]\n",
      "0.9696969696969697\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 9 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.95      0.93      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[19  0]\n",
      " [ 2 12]]\n",
      "0.9393939393939394\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "#Getting bananas from util functions\n",
    "DIR         = os.path.join(os.path.pardir, os.getcwd())          \n",
    "PATH        = os.path.join(DIR, \"images/\")                                  \n",
    "NONANOMPATH = \"bananas0.npy\"\n",
    "ANOMPATH    = \"bananas1.npy\"\n",
    "SUBTYPE     = \"Bananas\"  # leave as \"\" if not subtyping\n",
    "\n",
    "if not os.path.exists(NONANOMPATH) and not os.path.exists(ANOMPATH):\n",
    "    imgdf     = get_imgs(PATH)\n",
    "    imgdf     = subset_imgs(imgdf, SUBTYPE)\n",
    "    refdict   = build_referencedict(PATH, imgdf)\n",
    "    partimgs  = partition_images(PATH, imgdf, refdict)\n",
    "    part0     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==0]\n",
    "    part1     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==1]\n",
    "    np.save(ANOMPATH, part1, allow_pickle=True)\n",
    "    np.save(NONANOMPATH, part0, allow_pickle=True)\n",
    "    \n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "grid = {'C':[0.1,1,10,50,100,1000],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "for cycle in range(10):\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1]) # 50:50 distribution for the purpose of comparison\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "    \n",
    "    grid.fit(Xtrain, ytrain)\n",
    "\n",
    "    print('\\n', cycle, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66739e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 0 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85        15\n",
      "           1       0.76      1.00      0.87        13\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.88      0.87      0.86        28\n",
      "weighted avg       0.89      0.86      0.86        28\n",
      "\n",
      "[[11  4]\n",
      " [ 0 13]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80        16\n",
      "           1       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.79      0.79      0.78        28\n",
      "weighted avg       0.80      0.79      0.79        28\n",
      "\n",
      "[[12  4]\n",
      " [ 2 10]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        14\n",
      "           1       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.89      0.89      0.89        27\n",
      "weighted avg       0.89      0.89      0.89        27\n",
      "\n",
      "[[13  1]\n",
      " [ 2 11]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.92      0.92        27\n",
      "weighted avg       0.93      0.93      0.93        27\n",
      "\n",
      "[[ 9  1]\n",
      " [ 1 16]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 1 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.78      0.74      0.75        28\n",
      "weighted avg       0.78      0.79      0.78        28\n",
      "\n",
      "[[ 6  4]\n",
      " [ 2 16]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.96        28\n",
      "   macro avg       0.96      0.97      0.96        28\n",
      "weighted avg       0.97      0.96      0.96        28\n",
      "\n",
      "[[13  0]\n",
      " [ 1 14]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.94      0.93        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "[[14  2]\n",
      " [ 0 11]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90        16\n",
      "           1       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.89      0.91      0.89        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "[[13  3]\n",
      " [ 0 11]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 2 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        20\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.77      0.82      0.74        28\n",
      "weighted avg       0.87      0.75      0.76        28\n",
      "\n",
      "[[13  7]\n",
      " [ 0  8]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        10\n",
      "           1       0.83      0.83      0.83        18\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.77      0.77        28\n",
      "weighted avg       0.79      0.79      0.79        28\n",
      "\n",
      "[[ 7  3]\n",
      " [ 3 15]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.86      0.88      0.87        27\n",
      "weighted avg       0.90      0.89      0.89        27\n",
      "\n",
      "[[ 7  1]\n",
      " [ 2 17]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.88      0.91      0.89        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "[[14  3]\n",
      " [ 0 10]]\n",
      "\n",
      "##############################\n",
      " RANDOM SAMPLE # 3 \n",
      "##############################\n",
      "\n",
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78        13\n",
      "           1       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.84      0.81      0.82        28\n",
      "weighted avg       0.83      0.82      0.82        28\n",
      "\n",
      "[[ 9  4]\n",
      " [ 1 14]]\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        14\n",
      "           1       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.89      0.89      0.89        28\n",
      "weighted avg       0.89      0.89      0.89        28\n",
      "\n",
      "[[13  1]\n",
      " [ 2 12]]\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.97      0.96      0.96        27\n",
      "weighted avg       0.97      0.96      0.96        27\n",
      "\n",
      "[[11  1]\n",
      " [ 0 15]]\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        16\n",
      "           1       0.73      1.00      0.85        11\n",
      "\n",
      "    accuracy                           0.85        27\n",
      "   macro avg       0.87      0.88      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "[[12  4]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "poly_clf = svm.SVC(kernel='poly',degree=5,C=50,gamma=1)\n",
    "\n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "for cycle in range(4):\n",
    "    print('\\n##############################\\n RANDOM SAMPLE #',cycle,'\\n##############################\\n')\n",
    "    part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True,random_state=cycle)\n",
    "\n",
    "    idx=0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        idx+=1\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        Xtrain, Xtest = X[train_index], X[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "        ypred = poly_clf.fit(Xtrain,ytrain).predict(Xtest)\n",
    "        print('\\n', idx, 'th Report \\n')\n",
    "        print(classification_report(ytest, ypred))\n",
    "        print(confusion_matrix(ytest, ypred))\n",
    "        poly_clf.score(Xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c70e00",
   "metadata": {},
   "source": [
    "Again, seems like the results are relatively consistent. Getting decent accuracy on the classification and leaning more towards false negatives rather than false positives across datasets. Seems like a polynomial kernel is the best approach. In a bit we will try doing a similar analysis for 1 dataset classes and try to make the classes more and more unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3cba9",
   "metadata": {},
   "source": [
    "Now! The next approach here will be doing a decision tree classifier. We will use unbalanced classes for this and range over possible values. Might go with the whole class, might reduce it down in size to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64261e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4116ebb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      " Ratio is  1  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65        15\n",
      "           1       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.66      0.66      0.66        32\n",
      "weighted avg       0.66      0.66      0.66        32\n",
      "\n",
      "[[10  5]\n",
      " [ 6 11]]\n",
      "0.65625\n",
      "###################\n",
      " Ratio is  4  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        60\n",
      "           1       0.55      0.61      0.58        18\n",
      "\n",
      "    accuracy                           0.79        78\n",
      "   macro avg       0.71      0.73      0.72        78\n",
      "weighted avg       0.80      0.79      0.80        78\n",
      "\n",
      "[[51  9]\n",
      " [ 7 11]]\n",
      "0.7948717948717948\n",
      "###################\n",
      " Ratio is  7  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       111\n",
      "           1       0.29      0.43      0.34        14\n",
      "\n",
      "    accuracy                           0.82       125\n",
      "   macro avg       0.60      0.65      0.62       125\n",
      "weighted avg       0.85      0.82      0.83       125\n",
      "\n",
      "[[96 15]\n",
      " [ 8  6]]\n",
      "0.816\n",
      "###################\n",
      " Ratio is  10  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       156\n",
      "           1       0.45      0.56      0.50        16\n",
      "\n",
      "    accuracy                           0.90       172\n",
      "   macro avg       0.70      0.75      0.72       172\n",
      "weighted avg       0.91      0.90      0.90       172\n",
      "\n",
      "[[145  11]\n",
      " [  7   9]]\n",
      "0.8953488372093024\n",
      "###################\n",
      " Ratio is  13  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       211\n",
      "           1       0.31      0.50      0.38         8\n",
      "\n",
      "    accuracy                           0.94       219\n",
      "   macro avg       0.64      0.73      0.67       219\n",
      "weighted avg       0.96      0.94      0.95       219\n",
      "\n",
      "[[202   9]\n",
      " [  4   4]]\n",
      "0.9406392694063926\n",
      "###################\n",
      " Ratio is  16  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       253\n",
      "           1       0.32      0.62      0.42        13\n",
      "\n",
      "    accuracy                           0.92       266\n",
      "   macro avg       0.65      0.77      0.69       266\n",
      "weighted avg       0.95      0.92      0.93       266\n",
      "\n",
      "[[236  17]\n",
      " [  5   8]]\n",
      "0.9172932330827067\n",
      "###################\n",
      " Ratio is  19  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       297\n",
      "           1       0.27      0.40      0.32        15\n",
      "\n",
      "    accuracy                           0.92       312\n",
      "   macro avg       0.62      0.67      0.64       312\n",
      "weighted avg       0.94      0.92      0.93       312\n",
      "\n",
      "[[281  16]\n",
      " [  9   6]]\n",
      "0.9198717948717948\n",
      "###################\n",
      " Ratio is  22  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       347\n",
      "           1       0.31      0.33      0.32        12\n",
      "\n",
      "    accuracy                           0.95       359\n",
      "   macro avg       0.64      0.65      0.65       359\n",
      "weighted avg       0.95      0.95      0.95       359\n",
      "\n",
      "[[338   9]\n",
      " [  8   4]]\n",
      "0.9526462395543176\n",
      "###################\n",
      " Ratio is  25  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       391\n",
      "           1       0.54      0.47      0.50        15\n",
      "\n",
      "    accuracy                           0.97       406\n",
      "   macro avg       0.76      0.73      0.74       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      "\n",
      "[[385   6]\n",
      " [  8   7]]\n",
      "0.9655172413793104\n",
      "###################\n",
      " Ratio is  28  to 1 \n",
      "###################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       438\n",
      "           1       0.35      0.53      0.42        15\n",
      "\n",
      "    accuracy                           0.95       453\n",
      "   macro avg       0.67      0.75      0.70       453\n",
      "weighted avg       0.96      0.95      0.96       453\n",
      "\n",
      "[[423  15]\n",
      " [  7   8]]\n",
      "0.9514348785871964\n"
     ]
    }
   ],
   "source": [
    "NONANOMPATH = \"apples0.npy\"\n",
    "ANOMPATH    = \"apples1.npy\"\n",
    "SUBTYPE     = \"Apples\" \n",
    "\n",
    "\n",
    "\n",
    "for ratio in range(1,31,3):\n",
    "    part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "    part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "    print('###################\\n Ratio is ', ratio,' to 1 \\n###################')\n",
    "    part0, part1 = undersample(part0, part1,ratio = [ratio,1]) # 90:10 distribution for the decision tree\n",
    "    X = np.concatenate((\n",
    "                np.asarray(list(map(xfunc, part0))),\n",
    "                np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "    y = np.concatenate((\n",
    "                np.asarray(list(map(yfunc, part0))),\n",
    "                np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "\n",
    "    dec_tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "    ypred = dec_tree_clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    print(classification_report(ytest, ypred))\n",
    "    print(confusion_matrix(ytest, ypred))\n",
    "    print(dec_tree_clf.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583f6c7",
   "metadata": {},
   "source": [
    "And just because let's do the whole dataset too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5b8e45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% Test \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1518\n",
      "           1       0.25      0.45      0.32        22\n",
      "\n",
      "    accuracy                           0.97      1540\n",
      "   macro avg       0.62      0.72      0.65      1540\n",
      "weighted avg       0.98      0.97      0.98      1540\n",
      "\n",
      "[[1488   30]\n",
      " [  12   10]]\n",
      "0.9727272727272728\n",
      "\n",
      " 30% Test \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       911\n",
      "           1       0.35      0.46      0.40        13\n",
      "\n",
      "    accuracy                           0.98       924\n",
      "   macro avg       0.67      0.72      0.70       924\n",
      "weighted avg       0.98      0.98      0.98       924\n",
      "\n",
      "[[900  11]\n",
      " [  7   6]]\n",
      "0.9805194805194806\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=cycle)\n",
    "\n",
    "dec_tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "ypred = dec_tree_clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "print('50% Test \\n')\n",
    "print(classification_report(ytest, ypred))\n",
    "print(confusion_matrix(ytest, ypred))\n",
    "print(dec_tree_clf.score(Xtest,ytest))\n",
    "\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=cycle)\n",
    "\n",
    "dec_tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "ypred = dec_tree_clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "print('\\n 30% Test \\n')\n",
    "print(classification_report(ytest, ypred))\n",
    "print(confusion_matrix(ytest, ypred))\n",
    "print(dec_tree_clf.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e7152",
   "metadata": {},
   "source": [
    "# This is the better work! Cross validation not random state swapping\n",
    "\n",
    "Cycling thru the random state isn't good practice for these models. Will run an SVC grid search on these datasets and do a 4 fold cross validation on it. This one is for bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b84f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82        13\n",
      "           1       0.76      1.00      0.87        13\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.88      0.85      0.84        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[ 9  4]\n",
      " [ 0 13]]\n",
      "0.8461538461538461\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.94      0.90      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "[[16  0]\n",
      " [ 2  8]]\n",
      "0.9230769230769231\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87        13\n",
      "           1       0.81      1.00      0.90        13\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.91      0.88      0.88        26\n",
      "weighted avg       0.91      0.88      0.88        26\n",
      "\n",
      "[[10  3]\n",
      " [ 0 13]]\n",
      "0.8846153846153846\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.92      0.92        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "[[ 9  1]\n",
      " [ 1 15]]\n",
      "0.9230769230769231\n",
      "{'C': 100, 'degree': 6, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "grid = {'C':[0.1,1,10,50,100,1000],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=42)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    grid.fit(Xtrain, ytrain)\n",
    "    \n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfd09b",
   "metadata": {},
   "source": [
    "Now specifically running the poly kernel w degree 6 and C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b424464",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.96      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[[12  1]\n",
      " [ 0 13]]\n",
      "0.9615384615384616\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76        16\n",
      "           1       0.62      0.80      0.70        10\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.74      0.73        26\n",
      "weighted avg       0.76      0.73      0.73        26\n",
      "\n",
      "[[11  5]\n",
      " [ 2  8]]\n",
      "0.7307692307692307\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.96      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[[12  1]\n",
      " [ 0 13]]\n",
      "0.9615384615384616\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.84      0.84      0.84        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "[[ 8  2]\n",
      " [ 2 14]]\n",
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "clf = svm.SVC(kernel='poly',degree=6,C=100)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=42)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    ypred=clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    \n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, ypred))\n",
    "    print(confusion_matrix(ytest, ypred))\n",
    "    print(clf.score(Xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c815d88",
   "metadata": {},
   "source": [
    "Now trying an RBF kernel w C=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a69255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80        13\n",
      "           1       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.81      0.81      0.81        26\n",
      "weighted avg       0.81      0.81      0.81        26\n",
      "\n",
      "[[10  3]\n",
      " [ 2 11]]\n",
      "0.8076923076923077\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80        16\n",
      "           1       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.76      0.78      0.76        26\n",
      "weighted avg       0.78      0.77      0.77        26\n",
      "\n",
      "[[12  4]\n",
      " [ 2  8]]\n",
      "0.7692307692307693\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87        13\n",
      "           1       0.81      1.00      0.90        13\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.91      0.88      0.88        26\n",
      "weighted avg       0.91      0.88      0.88        26\n",
      "\n",
      "[[10  3]\n",
      " [ 0 13]]\n",
      "0.8846153846153846\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.76      0.74      0.75        26\n",
      "weighted avg       0.77      0.77      0.76        26\n",
      "\n",
      "[[ 6  4]\n",
      " [ 2 14]]\n",
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',C=1000)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=42)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    ypred=clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    \n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, ypred))\n",
    "    print(confusion_matrix(ytest, ypred))\n",
    "    print(clf.score(Xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a869f5",
   "metadata": {},
   "source": [
    "### Doing same stuff but with tires instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f54338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79        13\n",
      "           1       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.78      0.77      0.77        26\n",
      "weighted avg       0.78      0.77      0.77        26\n",
      "\n",
      "[[11  2]\n",
      " [ 4  9]]\n",
      "0.7692307692307693\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.94      0.92        26\n",
      "weighted avg       0.94      0.92      0.92        26\n",
      "\n",
      "[[14  2]\n",
      " [ 0 10]]\n",
      "0.9230769230769231\n",
      "{'C': 1000, 'degree': 4, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.85      0.85      0.85        13\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.85      0.85      0.85        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "[[11  2]\n",
      " [ 2 11]]\n",
      "0.8461538461538461\n",
      "{'C': 1000, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.57        10\n",
      "           1       0.73      0.69      0.71        16\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.64      0.64      0.64        26\n",
      "weighted avg       0.66      0.65      0.66        26\n",
      "\n",
      "[[ 6  4]\n",
      " [ 5 11]]\n",
      "0.6538461538461539\n",
      "{'C': 50, 'degree': 5, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "DIR         = os.path.join(os.path.pardir, os.getcwd())          \n",
    "PATH        = os.path.join(DIR, \"images/\")                                  \n",
    "NONANOMPATH = \"tires0.npy\"\n",
    "ANOMPATH    = \"tires1.npy\"\n",
    "SUBTYPE     = \"Tires\"  # leave as \"\" if not subtyping\n",
    "\n",
    "if not os.path.exists(NONANOMPATH) and not os.path.exists(ANOMPATH):\n",
    "    imgdf     = get_imgs(PATH)\n",
    "    imgdf     = subset_imgs(imgdf, SUBTYPE)\n",
    "    refdict   = build_referencedict(PATH, imgdf)\n",
    "    partimgs  = partition_images(PATH, imgdf, refdict)\n",
    "    part0     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==0]\n",
    "    part1     = [(tup[1], tup[2]) for tup in partimgs if tup[2]==1]\n",
    "    np.save(ANOMPATH, part1, allow_pickle=True)\n",
    "    np.save(NONANOMPATH, part0, allow_pickle=True)\n",
    "    \n",
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "grid = {'C':[0.1,1,10,50,100,1000],\n",
    "    'kernel':['rbf','poly', 'linear'],\n",
    "    'degree':[4,5,6],\n",
    "    'gamma': [1, 0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), grid, refit = True)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=42)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    grid.fit(Xtrain, ytrain)\n",
    "    \n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(confusion_matrix(ytest, grid.best_estimator_.predict(Xtest)))\n",
    "    print(grid.score(Xtest, ytest))\n",
    "    print(grid.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96234f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        13\n",
      "           1       1.00      0.69      0.82        13\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.88      0.85      0.84        26\n",
      "weighted avg       0.88      0.85      0.84        26\n",
      "\n",
      "[[13  0]\n",
      " [ 4  9]]\n",
      "0.8461538461538461\n",
      "\n",
      " 2 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.94      0.92        26\n",
      "weighted avg       0.94      0.92      0.92        26\n",
      "\n",
      "[[14  2]\n",
      " [ 0 10]]\n",
      "0.9230769230769231\n",
      "\n",
      " 3 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80        13\n",
      "           1       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.81      0.81      0.81        26\n",
      "weighted avg       0.81      0.81      0.81        26\n",
      "\n",
      "[[10  3]\n",
      " [ 2 11]]\n",
      "0.8076923076923077\n",
      "\n",
      " 4 th Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.95      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "[[ 9  1]\n",
      " [ 0 16]]\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "part0        = np.load(NONANOMPATH, allow_pickle=True)\n",
    "part1        = np.load(ANOMPATH, allow_pickle=True)\n",
    "\n",
    "clf = svm.SVC(kernel='poly',degree=5,C=100)\n",
    "\n",
    "part0, part1 = undersample(part0, part1,ratio = [1,1])\n",
    "X = np.concatenate((\n",
    "            np.asarray(list(map(xfunc, part0))),\n",
    "            np.asarray(list(map(xfunc, part1)))), axis=0)\n",
    "y = np.concatenate((\n",
    "            np.asarray(list(map(yfunc, part0))),\n",
    "            np.asarray(list(map(yfunc, part1)))), axis=0)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True,random_state=42)\n",
    "\n",
    "idx=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    idx+=1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X[train_index], X[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "    ypred=clf.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    \n",
    "    print('\\n', idx, 'th Report \\n')\n",
    "    print(classification_report(ytest, ypred))\n",
    "    print(confusion_matrix(ytest, ypred))\n",
    "    print(clf.score(Xtest, ytest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
